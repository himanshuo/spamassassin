what will this be used to determine spam or not? wiki, basic things on website



next steps:
1) use tornado + asyncio with python3                                                                   DONE
    make async
2)WILL SEND TEXT directly through post request.                                                         DONE
3)determine spamd size limit.                                                                           DONE
     DEFAULT MAX MESSAGE SIZE : 500 KB)
     CAN CUSTOMIZE TO MAKE IT MAX SIZE : 256 MB
        size is specified in bytes, as a positive integer greater than 0.
            For example, -s 500000
        CONF SETTING IS:
            -s max_size, --max-size=max_size
               can specify this in spamc/spamd config files.

	3.5) if too much then send in batches.
4)determine best practices for using subprocess with tornado                                            DONE
5) edit settings to not use email header info                                                           DONE
    STEPS:
        1) make edits to config file
            sudo vim /etc/spamassassin/local.cf
               (NOTE: there is a backup of this file in the same directory called local.cf.backup)
        2) restart spamassassin service using
            sudo /etc/init.d/spamassassin restart
        3)spamc < filename.txt
            (spamc -c <filename.txt to only see the score/neccesssary_to_consider_spam_score)
6)train spamassassin using osf data                                                                     DONE
        sudo sa-learn --progress --ham HAMFOLDER/*
        sudo sa-learn --sync

        then, to see the contents of the spam db: (note, spamassassin basically turns messages into hashes.)
        sudo sa-learn --dump [all|magic|data]

7)figure out how to improve learning capabilities:
    1) generate a "message" in the form of an email.                                                    DONE
        supplied text or html data is message body
        key:value pairs of metadata can be header.
            things to include in header:
                author: commenter name
                email: commenter email
                subject: project on which person is
                ip: ip address of author.
                Content-Type: text/plain
            can use url params as header directly and add auto headers.
            FROM TESTING, WHICH HEADERS ARE NECCESSARY:
    2) change spamassassin settings to what
            http://search.cpan.org/~robn/Text-SpamAssassin-2.001/lib/Text/SpamAssassin.pm describes     DONE
        1)ignore DUN/DUL ip addressess
        2)https://github.com/robn/Text-SpamAssassin/blob/master/examples/comment_spam_prefs.cf          DONE
        3)# percent HTML - what should these be? LET LEARNING THING DO IT                               DONE(learned)
        score HTML_00_10		0
        score HTML_10_20		0
        score HTML_20_30		0
        score HTML_30_40		0
        score HTML_40_50		0
        score HTML_50_60		0
        score HTML_60_70		0
        score HTML_70_80		0
        score HTML_80_90		0
        score HTML_90_100		0
        4)score DNS_FROM_RFCI_DSN		0                                                                DONE
        5)score RCVD_IN_NJABL_DUL 0                                                                      DONE
        6)score RCVD_IN_SORBS_DUL 0                                                                        DONE
        7)score RCVD_IN_MAPS_DUL 0                                                                         DONE
    3) give more than just spam or ham output. GIVE ANALYTICS!!! EASY AND LOOKS GOOD (if user specifies full_report). DONE
8) you can make seperate endpoints for different types of osf data: comments/ titles/ wikis/ ...
REMEMBER WHAT THE ENTREPENEURSHIP GUY SAID: DO STUFF. IT MAKES PEOPLE THINK YOU ARE LEGIT. JUST KEEP PRODUCING MORE CONTENT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
9) AUTOLEARNING                                                                                          DONE(autolearn if header>3 body>3 in either direction.)
10)user says to learn
    --procedure to allow for sa-learn sudo usage is described in the following link:
    http://askubuntu.com/questions/155791/how-do-i-sudo-a-command-in-a-script-without-being-asked-for-a-password
    --the file used for this is called call_sa-learn.sh. I made it 777 for our purposes. This is NOT
    safe for production.
11)file input                                                                                            DONE
12)multilanguage support                                                                                 DONE
13)presentation                                                                                          DONE
    1)learn bayseian filter joke
    2)fix too many files bug
    3)redo jmeter tests
    4)do accuracy tests again for osf_ham
14) split up input data into two categories and then test against it!
    1)MAKE python utility that goes through all the osf messages and then shows you message             DONE
        if you say "s" then puts into spam folder. else "h" means put in ham folder
    2)make a data.py file that basically has all the good descriptive functions to move the data around.DONE
    3)one by one add files learn small subset of files and then test against them. repeat.
15) figure out where this code is placed on osf server.                                                 DONE
    Docker. Micheal will help me setup that.
16) Actually set up server on Docker with the right configs
17) figure out where my service should be called from. And what features can I encorporate into it.
      Features:
        1)"mark as spam" flag for comments, wikis
            remove comment/wiki when marked as spam. make it show up in admin window.
        2)admin interface for COS to see various projects/comments and determine if they are spam
        3)route emails to service.
            Figure out where the emails are coming from. Ask Andrew.
        4)
18)add "mark as spam" flag for comments and wikis
    1) comments
        1) set up server again                                                                          DONE
        2) figure out where comments code is                                                            DONE
                project/views/node  configure_comments
                        this is called in the beginning to determine if comment is public/private.
                        NOT for whether it is a reply or not
                        commentLevel does this.
                        Each comment already has a report spam button.
                                SO, your thing is, if someone reports something as spam, you send it to spam assassin
                        each comment MUST have some way to know how nested it is.
                                used for comment replies to other comments
        3)check if something is spam when someone first posts comment.                                 DONE
                1)http://localhost:5000/api/v1/project/jrkqp/comments/discussion/?_=1427726212374
                        used to determine who is in the comment message discussion.
                        used when you first open the comment dialog.
                        DOES NOT have actual comment info
                2)when someone creates http://localhost:5000/api/v1/project/jrkqp/comment/             DONE
                        NOTE: this is different from ./comments/ which takes you to comment configs
                        ./comment/ takes you to project/views/comment.py add_comment()
                         can add a line to check if the comment is good or not in add_comment()
                         NEED to figure out how to make a simple web request within osf
        4) DO SOMETHING IF SOMETHING IS SPAM
            1) if someone marks as spam, then send to spam assassin to learn                           DONE
                when marked as spam, sent to http://localhost:5000/api/v1/project/jrkqp/comment/u6xd8/report/
            2) if spam assassin determines new comment is spam, then send to admin page.
19) check if a project is spam or not when user tries to make a project public.
    when makePublic button is called, the js reveals that makePublic js function is called.
    there are multiple js functions that are doing stuff to make various aspects of the project public
        entire thing, dropbox, google drive ...
        all point to "permissions/public"
    the various rules related to permissions all point to project/views/node
        the possible functions are project_set_privacy, project_before_set_public
        I THINK what I need to do is work in project_before_set_public and just make sure project is not spam.
        project_before_set_public is responsible for that alert popup that basically gives you info on
            Either can have extra check in here or somewhere else.
        project_set_privacy responsible for simply setting privacy to whatever the input is. make public or private.
        Given BOTH project_set_privacy and project_before_set_public. I think the latter is a better  option.
            SO YEA, project_before_set_public is currently only responsible for that little prompt.
            Your job is more than just a prompt, but I think what you can do is just inject your spam
            checking right here.
    if NOT SPAM, then normal prompt and normal make public
    if SPAM, then new prompt (hey user, your project seems to have spam. We will check it. Until then, cant make public)
        AND send it to admin page to be checked. Also should email this info since its very important. We will see.
    HOWTO:
        1) Add possibleSpam field to project.
        2) if spamassassin says spam, make possibleSpam=true.
            spamassassin should check:
                title, author, files, wikis, NOT comments.
        3) if spamassassin says not spam, then do normally.
20) There are False positives in the presentation service. Can possible see if spam assassin can fix this
    https://osf.io/view/spsp2015/
19)CREATE new admin page for flagged spam values.
    1) a new field in the Comment Model says possibleSpam. Another new field is archive.                    DONE
        Using is_deleted instead of archive. The idea is the same.
        Copied Edit method and changed it to make mark_as_possible_spam
            makes possible_spam=true
            Uses the same save=False thing that Edit method has. I think its used for testing.
                NOT modifieing comment thus ignoring that bit of code from Edit.
    2) new page checks all comments and puts ones that are marked as spam in a list
        Since new page is completely seperate from a addon, I think it should be entirely seperate.
        Note, cant be addon because "addon's" are things that the user can enable. User CANNOT enable
            spam_admin page.
        1)Going to call this new page spam_admin.                                                          DONE
        2)add a url routing to a new page.                                                                 DONE
            unclear howto/whereto add url. Going to just make it '/spam_admin/'
            Where to make new spam_admin page????
            Going to go ahead and make it parallel to project_views and addon_views and discovery_views.
            Going to call it: spam_admin_view
            NOTE: JSONRendered for api stuff. Just get data.
            NOTE: OSFWebRenderer for actual webpage

            DEFAULT is going to be spam_admin/comments thus both urls point to spam_admin_views/comments
                GET '/spam_admin/comments'
                GET '/spam_admin/'
                    these are both osfwebrenderer.
            JSONRenderer's will be
                GET '/spam_admin/comments/all'
                POST '/spam_admin/comment/spam/<cid>'        cid = comment id
                POST '/spam_admin/comment/not_spam/<cid>'        cid = comment id
                GET '/spam_admin/comment/details/<cid>'        cid = comment id
                OR PERHAPS THESE ARE ALREADY IMPLEMENTED!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                You might ONLY have to make the GET '/spam_admin/comments/all' page.
                    NOPE. You cannot since the list_comment

            BUT FOR NOW, just going to make a basic page. Just seeing if I can view it.





        3)put in basic html.											DONE
            Can copy from some other page. Possible from conferences page. I think thats actually a really good idea.
            HOW TO USE OSFWebRendered?
                you just link to a mako page.
                the view function is probably called first, but it isnt really the thing that calls the actual html function.
                    atleast i dont think. let me see another project.
                    Like all the jsonrenderers, a osfwebrenderer returns a dict. dict in this case is probably used as
                    context for the page.
                    LOTS of good stuff on html/js on cosdev. Make sure to read it before next step.
            I have url showing up.
            NOW, how to send in a list of comments?
                How to get all comments from database????
                    comment = Comment.load(kwargs.get('cid')) reveals that there are methods (load) that you don't know about
                    PERHAPS there is a a method that allows you to get all comments. OR even better, get all comments
                        via a certain query!!!!
                        return Comment.find(Q('node', 'eq', node) &
                            Q('user', 'ne', user) &
                            Q('date_created', 'gt', view_timestamp) &
                            Q('date_modified', 'gt', view_timestamp)).count() PERFECT.

                        DO GET a mongo object back. I think it is serializable.
                        WAIT. Whats going on right now?
                            Firstly, I have a route that points to my mako page. Then I need to populate the mako page
                            by a list of comments (make list in views).
                            To populate, I am using Comment.query(Q(...))
                            I get the query back and its all good.
                            HOWEVER, I need to serialize the returned query to json format for output.
                            BUT i can still checkout the query results. No one is stopping me.
                        PROBLEM the comments do not have possible_spam flag marked when someone marks as spam.
                        I THINK THAT IS OKAY. What needs to happend is that possible_spam needs to be marked ONLY
                            when spam_assassin marks the comment as spam.
                        THUS, find some very spammy text to send to spam assassin.
                            Found spammy text.
                        Still not marking as spam. BECAUSE NO CODE TO ACTUALLY DO SO YET.
                            if spam, then make possible_spam = True.
                            ALSO, add code to make that when listing spam, dont include comments that have
                            possible_spam flag=True.


                        To serialize each comment, you can copy some of the methods OR DIRECTLY IMPORT THEM
                                OR figure out a way to put them in some util file or something.
                                PROBABLY TRY IMPORTING FIRST.
                                ACTUALLY: the things you need are VERY DIFFERENT than what that serialize comment method
                                has. SO, probably your own serialize_comment method fight be good.

                                Okay, so making your own serialize_comments and serialize_comment methods.
                                    What to do when comment is anonymous?? For now, just say "anonymous"

                                WHAT FIELDS DO YOU NEED TO MAKE A JUDGEMENT ON WHAT THE COMMENT IS???
                                content, author, project, context (link to where the comment is used. It might make sense in context.)
                                    will also have comment id just to have a list of comments? NO. STUPID.
                                    BUT author url is good.
                                    DATE created is good. helps to show urgency of doing this.
                                    if something has subcomments, its probably legit.
                                            I suppose, you should show subcomments in this case instead of just saying there are subcomments
                                SO, fields are
                                    content                                                             DONE
                                    author full name                                                    DONE
                                    author url
                                    project name                                                        DONE
                                    project url
                                    context (a view context button that shows neighboring comments)
                                        subcomments (shown as part of context)
                                    date created/date modified. whatever is most recent.

				



        3.5) add code to make sure user does not see comments that are spam
            THIS INCLUDES:
                when listing spam, make sure comment.possible_spam=False
                when counting num comments that have not been seen, add possible_spam to query
        3.6) figure out how to get rest of useful fields for viewing a comment.
        3.7) handle anonymous comments properly
        4)figure out how to use knockout js										DONE
            need to use knockout to display list of spam comments
            Likely going to have a OSF python function that gets the list and formats it. Knockout then calls
            this osf url and just gets the json associated with it.
            HOWTO osfdev:
            Basically, you have a Knockout template that allows you to:
                create a model Comment
                create a viewmodel Comment to actually get updates on the comment set
            Firstly, make regular stuff appear on the web page.
                the way this is working is that the diff parts of the web page are created via class helpers.
                    name=content() has the content of the web page. this is where you can make a list.
                    SEE if you can add normal bootstrap stuff here.
                        OR look at other pages and find something with a list/dropdown thing.
                            http://localhost:5000/search/?q=*&page=1
            Okay, so there are a few things:
                html page: website/templates/spam_admin.mako.
                knockout js viewmodel module:
                js module: just a bunch of code for a specific task
                page js:
                webpack: have to specify js page to go with what html page in webpack.common.config.js
                           when putting the js onto the webpage, you do so via:
                            <script src=${"/static/public/js/wiki-edit-page.js" | webpack_asset}></script>

                3 simple things to do:
                    1)create viewmodel in website/static/js/logFeed.js
                    2)initialize and do what you need with viewmodel in website/static/pages/some-template-page.js
                    3)make viewmodel data show up in website/templates/some_template.mako

                flow of data is from: user GET request -> server -> webpack -> html -> talks to knockout module

            HAVING LOTS OF TROUBLE WITH GETTING JS MODULES TO WORK. WILL SPEND TIME SEPARETLY TO WORK IT OUT.
            FOR NOW, make page look good. Working with them bootstrap CSS classes.





    3) list of spam is populated onto page										DONE
        requires creating some function that calls some service that gives me all spam.
            need python function that returns this info
            need js function that retrives this data
	I THINK the issue currently is that they server and client arent communicating.
	PLAN:
		comments function is listing all comments. This is called BEFORE showing regular page.
		desired functionality:
			1) when you first go to page, you can see 30 comments.
			2) when you make decision, update first 30 comments list.
				delete comment for which decision was made THEN new 30 list.
			3) next button shows next 30 comments. 
		how to do:
			NOTE: no more than 30 comments on browser at a time.
			1) when you first go to page, initial data that shows up is just total num comments and initial auth stuff
				how do other pages pass info from view to template??
					looks like ${profile["fullname"]} is used in profile template.
						the appropriate functions that are called yield {'profile':{'fullname':...} ...}
						meaning you can just pass a dict and its fields are available in the mako template using ${{field_name}}
							you can also pass in nested dict's and thus you can use ${{field_name['nested_field_name']}}
							DONT DO THIS using mako template code. I WANT to do this via call to api using knockout.
			2) js will call list_comments to get initial data.
				list_comments will give ONLY 30 comments.
				list_comments will give a url for next set of comments. 
					list_comments/x where x is the page num for comment
						this means that list_comments/1 would yield first 30 comments.
						list_comments/2 yields next 30 comments. 
						NO NEED FOR THE URL.
			3) 

			SCRATCH ABOVE.
			NEW PLAN:
				1) server sends comments in batch sizes. (default 30)
					set server to send 30 comments at a time.
					set server to accept "amount" of comments to send at a time.
				2) js module just collects them all into a giant comments list.
					gets more data if the comments list is < ~90
						server will have to send some notification to js module to let it know that no more comments left.
				3) js module shows 30 per page. Stores rest. 
				4) SAME thing for initial comment set.
			4)FIGURE OUT HOW TO MAKE the array of comments actually show up on page.
				ViewModel takes in spamAdminComments array.
				idea is that when this array is updated, the ViewModel observable array is also updated. 
					HOWEVER, it looks like the viewmodel only takes in default original value. So this construct does not work. 
				SpamAdminCommentFeed uses osf.applybindings() to actually recursively bind the div to the ViewModel.
				INSIGHT!: I think all your methods actually need to be for the ViewModel. NOT for the Feed.
					NEXT QUESTION: where should I be calling get_comments????
						FOR SEARCH, there is a < data-bind="submit: Submit" > which leads to the submit method which calls the search method.
						I will need something similar for when user clicks spam or ham
						Initially, I need to just put get_comments in init method perhaps.
						WORKS!!!! yay!!!!
			


    4) button next to each spam info says SPAM or NOT SPAM						DONE
    5) if SPAM, then archive it. Also, remove the possibleSpam flag on it.
    6) if NOT SPAM, put the comment back where it belongs.
        1) To "remove a comment" just get all comments as they are normally gotten. The only difference
        is that you add a line that checks to make sure the attained comment is
        NOT possibleSpam AND NOT archived
        2) To "put comment back where it belongs", just remove the possibleSpam flag and archive Flag.
    7) MAKE SURE ONLY admin's can access this page.
    7) SECOND TAB for projects.
    8) list all projects that have possibleSpam flag.
    9) button allows cos people to have final word on whether spam or not.
    10)if not spam, then possileSpam=false. If spam, then checkedForSpam=true
            MIGHT HAVE TO DO SAME ARCHIVING THING. WE WILL SEE.
            ALSO, probably want to show entire text of project OR the relevent part that is spam.


20)HOW MANY COMMENTS TO SHOW AT ONCE?
    Probably want to show only like 30 on a page.
    Make it so that you can refresh page and get new list of comments
    AND make it so that when you finish decision on a comment, that you can go ahead and u
    ALSO want a number up top that tells you how many comments are left.
21)when spam_admin says something is spam, automatically train spam assassin.
    SAME for not spam.
21) Make sure your code is injected in ALL Places.
    when someone edits comment, spam filter should run.
22) run tests


DO SAME FOR PROJECTS
23)Code for when making a private project is inside project/views/node. We are editing project_before_set_public
	to check that project is not spam before making it public. We are NOT deleting project.
24) The things inside the project that will be checked are:
		title, authors, wiki, date created, date updated, recent activity list, citations, tags, components, contributors list,
		THEN check each file individually.
24.1)figure out how to get each of these things from a project:
	1) where to get project from?
		for spam_admin page, this will be different. 
		for project/views/node/project_before_set_public, you just use the kwargs['project']
			this gives you a Node object.
			Node object has notable fields: 
					date_created, is_public, visible_contributor_ids, wiki_pages_current, title, description, category, creator, contributors, tags,
			Node object has notable methods:
					visible_contributors()
					parents()
					admin_contributors()			
	2)where to get x from?
		I can use direct fields of node. HOWEVER, i want to do it PROPER way. Proper way is bing done by actual html page. SO, good to follow that.
		looks like the nodeTitleEditable span is being populated with title. 
			node is passed in as a dict. It is using the mako templates thing where it passes in a dict for use by the template.
			yes, it is populated by node dict.
			SEEN in project/views/node view_project()
				the function being used to make node proper is "_view_project"
					thus function will give you:
						title, description, dates, tags, category (to determine if it is a project.), author username, 
			THUS, node now refers to result of _view_project()
		
	x=	title				node['title']                    GOOD.
		authors				node['user']['fullname']    	 GOOD.
		emails				node['user']['emails']		 GOOD.
		wiki				NodeWikiPage.find(Q('node','eq',node))  GOOD.
		date created			node[.]				 GOOD.
		date updated			node[.] 			 GOOD.
		recent activity list		code I found. 			 GOOD.
		citations			hmmm, maybe dont include this. its weird.
		tags				node[.]				 GOOD.
		components			TODO node.nodes  WILL HAVE TO CALL THIS FUNCTION FOR EACH COMPONENT. woahhhhhh
		contributors list		node['contributors']
		each individual file		TODO
	how Node works:
		top level node is a project. Each project can have subprojects. Each subproject is called a component. A component can be any of hypothesis, methods and procedures, prodcedure, instrumentation, data, analysis, communication, other. Each component is also a node. All nodes look the same -> a project looks the same as a component.
	can use node.project_or_component() to determine if something is a project or a component of a project

OKAY, so how do you want to split this up??? Definitely, one for all the diff parts of the of the current node (title, authors, wiki...). Recursively for each component. One for each file. 
		
24.5) FIGURE OUT PYTHON IMPORTING. LAZY IMPORTING? WHATS GOING ON?			
	
	
25)if the project(main contents OR any single file) is seen as spam, dont allow it to be made public
26)add project to spam_admin page. Send email to let people know hey, there is some project that is being considered spam.
27)if project IS spam, dont allow it to be public ever. If project IS NOT spam, make it public.
	CURRENTLY DOES NOT ACTUALLY STOP PROJECT FROM GOING PUBLIC!!!!!
28)make stuff appear on page for project.
!!!!!!!!!!!!!!!!!!!!!! OKAY PLAN THIS OUT CAREFULLY!!!!!!!!!!!!!!!!!!!!!!!!!!
	1) put template of how project will look on mako page
	2) 



Confident that spamd is running in parallel                                                             DONE
https://svn.apache.org/repos/asf/spamassassin/branches/3.4/spamd/README section on performance.
    just need to determine num max-children running in parallel on my machine.
       using a special algorithm that maximizes this value.
       FOR TESTING, will make min parallel processes 3 and max 5. Note: these are "children"
            file to do this is: sudo vim /etc/default/spamassassin

            Can check that they are running in parallel using sandbox.sh


what to understand about async and tornado. with tornado,
    you DO NOT actually make it so users are put on different threads.
    INSTEAD, everyone comes to a single thread AND their action is put on the ioloop.
    their action is run. Others actions are also run. While running, the ioloop does not care whats happening.
    the ioloop accepts more requests and just adds them onto the queue of things to do.
    THUS you basically have multiple people getting things done on the same thread concurrently.
    The ioloop is also always listening. if someone finishes a task, the ioloop runs the appropriate code for when that task is finished.




TODO:
1)make a super spam user that can view the spam_admin page.
	how to check if a user is logged in
		@collect_auth  - puts auth into kwargs['auth']
		@must_be_logged_in - makes sure that the kwargs['auth'] is logged in.
		
		need to make a new decorator @is_spam_admin that checks to see if kwargs['auth'] is spam_admin. 
		
		
	how to get auth of current user
		auth.user will get you user info. What part of this do we use to make sure it is actually spam_admin user? FOR NOW, we can just check to see if email is spam_admin@cos.com and name=spam_admin.
	how to create a new user?
		just normal user creation.
		can check what is being called here.

		
1)spam_flagged_count num times this comment has been marked as spam. if >0 then put in admin_page. 
2)is_spam_confirmed  no longer check if this thing is spam  TRUE, FALSE, NONE
3)have some way to 
4)talk to steve about ginneys comment.
5)todo: if user repeatedly spams, just say everything by that user is spam.



TEST RESULTS
    for large file input (488KB. max is 500KB), 5 threads with 5  calls each, async takes avg of 29s and sync 61s
    for normal input (500 bytes), 5 threads with 20 calls each- async: sync:





Not sure if this exactly relates, but if we are changing the the Flask app then can we also change process_rules?
Currently, process_rules turns the 
if callable(rule.view_func_or_data):

            view_func = rule.view_func_or_data
            renderer_name = getattr(
                rule.renderer,
                '__name__',
                rule.renderer.__class__.__name__
            )
            endpoint = '{}__{}'.format(
                renderer_name,
                rule.view_func_or_data.__name__
            )
            view_functions[endpoint] = rule.view_func_or_data
